{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e529f290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mQuestion: Find the latest research in LLMs and summarize it, and calculate tokens needed for 3 million words.\n",
      "\n",
      "Thought: Let's break this down into two tasks. First, I'll find the latest research in LLMs and summarize it. Then, I'll calculate the tokens needed for 3 million words.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Web Search\",\n",
      "  \"action_input\": \"latest research in LLMs\"\n",
      "}\n",
      "```\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m['The latest in LLM research with a hand-curated, topic-organized list of over 200 research papers from 2025.', 'With advancements in LLMs across industries, Booth faculty are key figures leading broader application of language models. We highlight a few recent ...', 'Beyond the Experiment: What Academic Research Reveals About Cognitive Stretching in LLMs. https://medium.com/@ResponseLab/beyond-the ...', 'This article explores the future of large language models by delving into developments like self-training, fact-checking, and sparse ...', 'The LLMs Research Paper in January 2025 showcases several groundbreaking advancements in size reduction and enhanced performance.', 'It include new tips, insights and developments around important LLM research areas such as scaling, agents, efficiency, hallucination, architectures, prompt ...', 'Explore the latest LLM breakthroughs from March 2025. Discover research papers on performance boosts, memory efficiency, Instruction Tuning, ...', 'This article examines the latest trends and innovations shaping the future of AI LLMs, highlighting advancements that defined 2024 and that are also set to ...', \"I've been trying to find a good mix of resources to stay on top of everything â€” research, tooling, evals, real-world use cases, etc ...\", 'In this article, I summarizes important LLM papers published during April 2024, covering topics such as model reasoning, performance enhancement, or even ...']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought: Now that I have the latest research in LLMs, I'll summarize it using the Structured Summary tool.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Structured Summary\",\n",
      "  \"action_input\": \"latest research in LLMs\"\n",
      "}\n",
      "```\n",
      "\n",
      "\u001b[0mRaw LLM Response: ```json\n",
      "{\n",
      "\t\"title\": \"Advancements in Large Language Models (LLMs)\",\n",
      "\t\"summary\": \"Recent research in LLMs has focused on scaling up model sizes, leading to significant improvements in natural language understanding and generation capabilities. Specifically, researchers have explored the use of massive datasets, novel architectures, and efficient training algorithms to develop more accurate and efficient LLMs. These advancements have far-reaching implications for applications such as language translation, text summarization, and chatbots.\"\n",
      "}\n",
      "```\n",
      "\n",
      "Observation: \u001b[38;5;200m\u001b[1;3m{'title': 'Advancements in Large Language Models (LLMs)', 'summary': 'Recent research in LLMs has focused on scaling up model sizes, leading to significant improvements in natural language understanding and generation capabilities. Specifically, researchers have explored the use of massive datasets, novel architectures, and efficient training algorithms to develop more accurate and efficient LLMs. These advancements have far-reaching implications for applications such as language translation, text summarization, and chatbots.'}\u001b[0m\n",
      "Thought:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThought: Now that I have summarized the latest research in LLMs, I'll calculate the tokens needed for 3 million words.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Python REPL\",\n",
      "  \"action_input\": \"3 * 10**6 * 1.33\"\n",
      "}\n",
      "```\n",
      "\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mAction:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Python REPL\",\n",
      "  \"action_input\": \"print(3 * 10**6 * 1.33)\"\n",
      "}\n",
      "```\n",
      "\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m3990000.0\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought: I have the summary of the latest research in LLMs and the calculation of tokens needed for 3 million words. I'll provide the final answer.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"The latest research in LLMs focuses on scaling up model sizes, leading to significant improvements in natural language understanding and generation capabilities. Recent advancements include the use of massive datasets, novel architectures, and efficient training algorithms. For 3 million words, approximately 3,990,000 tokens are needed, assuming 1 word = 1.33 tokens.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "ðŸ§  Final Answer:\n",
      " {'input': '\\n1. Find the latest research in LLMs and summarize it using the Structured Summary tool.\\n2. Calculate how many tokens are needed for 3 million words using the Python REPL tool, assuming 1 word = 1.33 tokens.\\n', 'output': 'The latest research in LLMs focuses on scaling up model sizes, leading to significant improvements in natural language understanding and generation capabilities. Recent advancements include the use of massive datasets, novel architectures, and efficient training algorithms. For 3 million words, approximately 3,990,000 tokens are needed, assuming 1 word = 1.33 tokens.'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.agents import initialize_agent, AgentType, Tool\n",
    "from langchain_community.utilities import SerpAPIWrapper\n",
    "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
    "os.environ[\"SERPAPI_API_KEY\"] = \"bd0d819e093e6c8acf32d6aaab551208bb2f15b199966fa215daa790ba73c33d\"\n",
    "\n",
    "llm = ChatGroq(api_key=os.environ[\"GROQ_API_KEY\"], model_name=\"llama3-70b-8192\")\n",
    "\n",
    "search_tool = SerpAPIWrapper()\n",
    "python_tool = PythonREPLTool()\n",
    "\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"title\", description=\"Title of the research topic\"),\n",
    "    ResponseSchema(name=\"summary\", description=\"Short summary in 2-3 lines\"),\n",
    "]\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"\"\"You are a research assistant. Provide a short summary about: {topic}\n",
    "Return the response in valid JSON format as shown below. Ensure proper JSON syntax with correct commas and quotes:\n",
    "```json\n",
    "{format_instructions}\n",
    "```\"\"\",\n",
    "    input_variables=[\"topic\"],\n",
    "    partial_variables={\"format_instructions\": output_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "def structured_summary(topic: str) -> dict:\n",
    "    prompt = prompt_template.format(topic=topic)\n",
    "    try:\n",
    "        response = llm.invoke(prompt)\n",
    "        raw_content = response.content.strip()\n",
    "        print(\"Raw LLM Response:\", raw_content)  \n",
    "\n",
    "        json_match = re.search(r'```json\\n([\\s\\S]*?)\\n```', raw_content)\n",
    "        if json_match:\n",
    "            json_str = json_match.group(1)\n",
    "        else:\n",
    "            json_str = raw_content\n",
    "\n",
    "        parsed = output_parser.parse(json_str)\n",
    "        return parsed\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON Parsing Error: {e}\")\n",
    "        return {\"title\": \"Error\", \"summary\": f\"Failed to parse LLM response: {str(e)}\"}\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected Error: {e}\")\n",
    "        return {\"title\": \"Error\", \"summary\": f\"Unexpected error: {str(e)}\"}\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Web Search\",\n",
    "        func=search_tool.run,\n",
    "        description=\"Use this tool to search for recent research using SerpAPI\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Python REPL\",\n",
    "        func=python_tool.run,\n",
    "        description=\"Useful for calculations and logic\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Structured Summary\",\n",
    "        func=structured_summary,\n",
    "        description=\"Summarize a research topic in 2â€“3 lines with title\"\n",
    "    )\n",
    "]\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "query = \"\"\"\n",
    "1. Find the latest research in LLMs and summarize it using the Structured Summary tool.\n",
    "2. Calculate how many tokens are needed for 3 million words using the Python REPL tool, assuming 1 word = 1.33 tokens.\n",
    "\"\"\"\n",
    "try:\n",
    "    result = agent.invoke(query)\n",
    "    print(\"\\nðŸ§  Final Answer:\\n\", result)\n",
    "except Exception as e:\n",
    "    print(f\"Agent Execution Error: {e}\")\n",
    "    print(\"\\nðŸ§  Final Answer:\\n\", {\"error\": f\"Agent failed to execute: {str(e)}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc927eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
