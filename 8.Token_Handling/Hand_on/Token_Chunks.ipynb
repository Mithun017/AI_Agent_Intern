{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ce62443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " chunk 0: What Is Machine Learning? \n",
      "Machine learning (ML) is a branch of artificial intelligence that enables computers to \n",
      "learn from data—without being explicitly programmed. Instead of following rigid \n",
      "instructions, ML systems analyze patterns and improve their performance with \n",
      "experience.\n",
      "\n",
      " chunk 1: experience. \n",
      "Imagine teaching a child to recognize birds. You show examples—photos, sounds, \n",
      "movements—and eventually, they learn to identify birds without needing a checklist. ML \n",
      "works similarly: it uses data to train models that make predictions or decisions. \n",
      " \n",
      "How It Works\n",
      "\n",
      " chunk 2: How It Works \n",
      "The process typically involves: \n",
      "1. Data Collection: Huge volumes of relevant data are gathered. \n",
      "2. Training a Model: This data is used to teach the algorithm what patterns to \n",
      "recognize. \n",
      "3. Evaluation: The model is tested with new data to check its accuracy.\n",
      "\n",
      " chunk 3: 4. Improvement: Based on the results, the model is refined. \n",
      " \n",
      "Types of Machine Learning \n",
      "• Supervised Learning: The model learns from labeled data (e.g., emails marked \n",
      "“spam” or “not spam”). \n",
      "• Unsupervised Learning: Finds hidden patterns in unlabeled data (e.g., grouping\n",
      "\n",
      " chunk 4: customers by behavior). \n",
      "• Reinforcement Learning: The model learns by trial and error, receiving \n",
      "feedback—like training a robot to walk.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "loader = PyPDFLoader(r\"C:\\Users\\MITHUN\\Desktop\\STUDIES\\Intership\\2.5K Ai Agents Intern\\8.Token_Handling\\Hand_on\\What Is Machine Learning.pdf\")\n",
    "documents = loader.load()\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=20,\n",
    ")\n",
    "chunks = splitter.split_documents(documents)\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"\\n chunk {i}: {chunk.page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48dc9a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MITHUN\\AppData\\Local\\Temp\\ipykernel_14396\\2478517394.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
      "c:\\Users\\MITHUN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\MITHUN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MITHUN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\MITHUN\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: Machine learning is amazing.\n",
      "Embedding (first 5 dims): [-0.02847002074122429, -0.09029371291399002, 0.09246505051851273, -0.009944604709744453, -0.007828949950635433]\n",
      "------\n",
      "Sentence 2: Artificial intelligence is the future.\n",
      "Embedding (first 5 dims): [-0.031597383320331573, -0.0072324639186263084, 0.036698997020721436, -0.026985710486769676, -0.027607988566160202]\n",
      "------\n",
      "Sentence 3: Cats are great pets.\n",
      "Embedding (first 5 dims): [0.07553702592849731, -0.005085863173007965, 0.09948339313268661, 0.008595701307058334, -0.13170868158340454]\n",
      "------\n",
      "Sentence 4: The sky is blue.\n",
      "Embedding (first 5 dims): [0.01791948825120926, 0.01352880708873272, 0.04279670491814613, 0.016718193888664246, 0.029823752120137215]\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "sentences = [\n",
    "    \"Machine learning is amazing.\",\n",
    "    \"Artificial intelligence is the future.\",\n",
    "    \"Cats are great pets.\",\n",
    "    \"The sky is blue.\"\n",
    "]\n",
    "\n",
    "embeddings = embedding_model.embed_documents(sentences)\n",
    "\n",
    "for i, (sentence, vector) in enumerate(zip(sentences, embeddings)):\n",
    "    print(f\"Sentence {i+1}: {sentence}\")\n",
    "    print(f\"Embedding (first 5 dims): {vector[:5]}\")\n",
    "    print(\"------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb560b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MITHUN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\MITHUN\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization Initiated\n",
      "['apple', 'is', 'a', 'fruit']\n",
      "[6207, 2003, 1037, 5909]\n",
      "[ 0.07331281  0.04409567  0.00852461  0.04129385 -0.03418823]\n",
      "[ 0.03402128  0.003408   -0.02938359  0.04302779  0.000374  ]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\") # bert -> bidirectional encoder\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "text1 = \"Apple is a fruit\"\n",
    "text2 = \"Mango is also a fruit\"\n",
    "\n",
    "tokens = tokenizer.tokenize(text1)\n",
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "print(\"Tokenization Initiated\")\n",
    "print(tokens)\n",
    "print(token_ids)\n",
    "\n",
    "embedding1= model.encode(text1)\n",
    "embedding2= model.encode(text2)\n",
    "\n",
    "print(embedding1[:5])\n",
    "print(embedding2[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9895a78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
